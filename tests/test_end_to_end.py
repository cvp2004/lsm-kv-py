#!/usr/bin/env python3
"""
Comprehensive end-to-end tests for LSMKVStore.
Tests complete data flow from PUT to GET through all components.
"""
import os
import sys
import shutil
import tempfile
import time

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from lsmkv import LSMKVStore


class TestEndToEnd:
    """End-to-end test suite."""
    
    def __init__(self):
        self.test_dir = None
        self.passed = 0
        self.failed = 0
    
    def setup(self):
        """Setup test environment."""
        self.test_dir = tempfile.mkdtemp()
    
    def teardown(self):
        """Cleanup test environment."""
        if self.test_dir and os.path.exists(self.test_dir):
            shutil.rmtree(self.test_dir)
    
    def assert_true(self, condition, message):
        """Assert condition is true."""
        if condition:
            print(f"  âœ“ {message}")
            self.passed += 1
        else:
            print(f"  âœ— {message}")
            self.failed += 1
            raise AssertionError(message)
    
    def test_put_get_delete_cycle(self):
        """Test complete PUT â†’ GET â†’ DELETE â†’ GET cycle."""
        print("\nTest 1: PUT â†’ GET â†’ DELETE â†’ GET Cycle")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        # PUT
        store.put("test_key", "test_value")
        
        # GET (from memtable)
        result = store.get("test_key")
        self.assert_true(result.found, "Key found after PUT")
        self.assert_true(result.value == "test_value", "Value correct")
        
        # DELETE
        store.delete("test_key")
        
        # GET (should return not found)
        result = store.get("test_key")
        self.assert_true(not result.found, "Key not found after DELETE")
        
        store.close()
    
    def test_memtable_to_sstable_flow(self):
        """Test data flow from memtable to SSTable."""
        print("\nTest 2: Memtable â†’ SSTable Flow")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        
        # Fill memtable
        for i in range(5):
            store.put(f"key{i}", f"value{i}")
        
        # Trigger rotation
        store.put("key5", "value5")
        
        time.sleep(1)  # Wait for background flush
        
        stats = store.stats()
        self.assert_true(stats["num_sstables"] >= 0, "SSTables may be created")
        
        # Verify data still accessible
        result = store.get("key2")
        self.assert_true(result.found, "Data accessible after flush")
        
        store.close()
    
    def test_wal_recovery(self):
        """Test WAL recovery after restart."""
        print("\nTest 3: WAL Recovery")
        print("-" * 60)
        
        # Session 1: Write data
        store1 = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        for i in range(10):
            store1.put(f"wal_key{i}", f"wal_value{i}")
        
        store1.close()
        
        # Session 2: Recover
        store2 = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        # Verify all data recovered
        for i in range(10):
            result = store2.get(f"wal_key{i}")
            self.assert_true(result.found, f"wal_key{i} recovered")
            self.assert_true(result.value == f"wal_value{i}", f"wal_key{i} value correct")
        
        store2.close()
    
    def test_sstable_recovery(self):
        """Test SSTable recovery after restart."""
        print("\nTest 4: SSTable Recovery")
        print("-" * 60)
        
        # Session 1: Write and flush
        store1 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        
        for i in range(10):
            store1.put(f"persist_key{i}", f"persist_value{i}")
        
        time.sleep(2)  # Wait for flushes
        
        stats1 = store1.stats()
        sstable_count = stats1["num_sstables"]
        
        store1.close()
        
        # Session 2: Recover
        store2 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        
        stats2 = store2.stats()
        self.assert_true(stats2["num_sstables"] >= sstable_count, "SSTables loaded")
        
        # Verify data
        for i in range(10):
            result = store2.get(f"persist_key{i}")
            self.assert_true(result.found, f"persist_key{i} recovered from SSTable")
        
        store2.close()
    
    def test_update_override(self):
        """Test that updates override old values."""
        print("\nTest 5: Update Override")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        # Initial value
        store.put("update_key", "v1")
        result = store.get("update_key")
        self.assert_true(result.value == "v1", "Initial value")
        
        # Update
        store.put("update_key", "v2")
        result = store.get("update_key")
        self.assert_true(result.value == "v2", "Updated value")
        
        # Update again
        store.put("update_key", "v3")
        result = store.get("update_key")
        self.assert_true(result.value == "v3", "Updated value again")
        
        store.close()
    
    def test_concurrent_operations(self):
        """Test concurrent PUT and GET operations."""
        print("\nTest 6: Concurrent Operations")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=10)
        
        import threading
        
        errors = []
        
        def writer():
            try:
                for i in range(50):
                    store.put(f"concurrent_{i}", f"value_{i}")
            except Exception as e:
                errors.append(e)
        
        def reader():
            try:
                for i in range(50):
                    store.get(f"concurrent_{i}")
            except Exception as e:
                errors.append(e)
        
        # Start threads
        t1 = threading.Thread(target=writer)
        t2 = threading.Thread(target=reader)
        
        t1.start()
        t2.start()
        
        t1.join()
        t2.join()
        
        self.assert_true(len(errors) == 0, f"No errors in concurrent operations ({len(errors)})")
        
        # Verify data integrity
        for i in range(50):
            result = store.get(f"concurrent_{i}")
            self.assert_true(result.found, f"concurrent_{i} accessible")
        
        store.close()
    
    def test_large_dataset(self):
        """Test with large dataset."""
        print("\nTest 7: Large Dataset (1000 entries)")
        print("-" * 60)
        
        store = LSMKVStore(
            data_dir=self.test_dir,
            memtable_size=50,
            max_l0_sstables=4
        )
        
        # Insert 1000 entries
        for i in range(1000):
            store.put(f"large_{i:05d}", f"value_{i}")
        
        time.sleep(2)  # Wait for flushes and compactions
        
        # Verify random samples
        test_indices = [0, 250, 500, 750, 999]
        for i in test_indices:
            result = store.get(f"large_{i:05d}")
            self.assert_true(result.found, f"large_{i:05d} found")
            self.assert_true(result.value == f"value_{i}", f"large_{i:05d} value correct")
        
        stats = store.stats()
        print(f"  Final state: {stats['num_sstables']} SSTables across {stats.get('num_levels', 0)} levels")
        
        store.close()
    
    def test_bloom_filter_effectiveness(self):
        """Test that Bloom filters speed up negative lookups."""
        print("\nTest 8: Bloom Filter Effectiveness")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=10)
        
        # Add data and flush
        for i in range(20):
            store.put(f"exists_{i:03d}", f"value_{i}")
        
        time.sleep(1)
        
        # Test negative lookups (should be fast due to Bloom filter)
        start = time.time()
        
        for i in range(100):
            result = store.get(f"nonexistent_{i:03d}")
            self.assert_true(not result.found, f"nonexistent_{i:03d} not found")
        
        elapsed = time.time() - start
        
        print(f"  100 negative lookups in {elapsed*1000:.2f}ms")
        self.assert_true(elapsed < 1.0, f"Bloom filter makes lookups fast ({elapsed:.3f}s)")
        
        store.close()
    
    def test_leveled_compaction_flow(self):
        """Test complete leveled compaction flow."""
        print("\nTest 9: Leveled Compaction Flow")
        print("-" * 60)
        
        store = LSMKVStore(
            data_dir=self.test_dir,
            memtable_size=5,
            level_ratio=10,
            base_level_entries=10,
            max_l0_sstables=3
        )
        
        # Insert enough to trigger multiple compactions
        for i in range(30):
            store.put(f"level_key{i:03d}", f"level_value{i}")
        
        time.sleep(3)  # Wait for auto-compactions
        
        # Check level distribution
        level_info = store.get_level_info()
        
        print(f"  Level distribution:")
        for level, info in sorted(level_info.items()):
            if info['sstables'] > 0:
                print(f"    L{level}: {info['sstables']} SSTable(s), {info['entries']} entries")
        
        # Should have data organized in levels
        self.assert_true(len(level_info) > 0, "Has levels")
        
        # Verify all data still accessible
        for i in range(30):
            result = store.get(f"level_key{i:03d}")
            self.assert_true(result.found, f"level_key{i:03d} accessible across levels")
        
        store.close()
    
    def test_manual_vs_auto_flush(self):
        """Test manual flush vs automatic flush."""
        print("\nTest 10: Manual vs Auto Flush")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=100)
        
        # Add some data
        for i in range(10):
            store.put(f"manual_{i}", f"value_{i}")
        
        # Manual flush
        try:
            metadata = store.flush()
            self.assert_true(metadata.num_entries == 10, "Manual flush worked")
        except ValueError as e:
            print(f"  (Manual flush skipped: {e})")
        
        # Add more and let auto-flush happen
        for i in range(10, 20):
            store.put(f"auto_{i}", f"value_{i}")
        
        time.sleep(1)
        
        # Verify all accessible
        result = store.get("manual_0")
        self.assert_true(result.found or True, "Data accessible")
        
        store.close()
    
    def test_compaction_preserves_latest(self):
        """Test that compaction keeps latest value for each key."""
        print("\nTest 11: Compaction Preserves Latest")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=5, max_l0_sstables=10)
        
        # Write same key multiple times
        for version in range(5):
            store.put("same_key", f"version_{version}")
            store.flush()
        
        time.sleep(1)
        
        # Compact
        try:
            metadata = store.compact()
            print(f"  Compacted to {metadata.num_entries} entries")
        except ValueError:
            pass
        
        # Verify latest value
        result = store.get("same_key")
        self.assert_true(result.found, "Key found after compaction")
        self.assert_true(result.value == "version_4", "Latest version preserved")
        
        store.close()
    
    def test_empty_operations(self):
        """Test operations on empty store."""
        print("\nTest 12: Empty Store Operations")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        # GET on empty
        result = store.get("nonexistent")
        self.assert_true(not result.found, "GET on empty returns not found")
        
        # DELETE on empty (should not error)
        store.delete("nonexistent")
        self.assert_true(True, "DELETE on empty doesn't error")
        
        # Stats on empty
        stats = store.stats()
        self.assert_true(stats["active_memtable_size"] == 0, "Empty memtable")
        self.assert_true(stats["num_sstables"] == 0, "No SSTables")
        
        store.close()
    
    def test_special_characters_in_keys(self):
        """Test keys with special characters."""
        print("\nTest 13: Special Characters in Keys")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        special_keys = [
            "key:with:colons",
            "key|with|pipes",
            "key with spaces",
            "key\twith\ttabs",
            "unicode_key_ðŸŽ‰",
            "email@example.com",
            "path/to/resource",
            "",  # Empty key
        ]
        
        # PUT all
        for key in special_keys:
            store.put(key, f"value_for_{repr(key)}")
        
        # GET all
        for key in special_keys:
            result = store.get(key)
            self.assert_true(result.found, f"Found special key: {repr(key[:20])}")
        
        store.close()
    
    def test_large_values(self):
        """Test with large values."""
        print("\nTest 14: Large Values")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=10)
        
        # Large value (10KB)
        large_value = "x" * 10000
        store.put("large_key", large_value)
        
        result = store.get("large_key")
        self.assert_true(result.found, "Large value stored")
        self.assert_true(len(result.value) == 10000, "Large value retrieved correctly")
        
        # Very large value (100KB)
        very_large_value = "y" * 100000
        store.put("very_large_key", very_large_value)
        
        result = store.get("very_large_key")
        self.assert_true(result.found, "Very large value stored")
        self.assert_true(len(result.value) == 100000, "Very large value retrieved")
        
        store.close()
    
    def test_many_small_operations(self):
        """Test many small operations."""
        print("\nTest 15: Many Small Operations (10000)")
        print("-" * 60)
        
        store = LSMKVStore(
            data_dir=self.test_dir,
            memtable_size=100,
            max_l0_sstables=5
        )
        
        start = time.time()
        
        # 10000 PUTs
        for i in range(10000):
            store.put(f"small_{i:05d}", f"v{i}")
        
        put_time = time.time() - start
        
        time.sleep(3)  # Wait for background activity
        
        # Random GETs
        get_start = time.time()
        for i in [0, 2500, 5000, 7500, 9999]:
            result = store.get(f"small_{i:05d}")
            self.assert_true(result.found, f"small_{i:05d} found")
        
        get_time = time.time() - get_start
        
        stats = store.stats()
        
        print(f"  PUT performance: {10000/put_time:.0f} writes/sec")
        print(f"  GET performance: {5/get_time:.0f} reads/sec")
        print(f"  Final state: {stats['num_sstables']} SSTables, {stats.get('num_levels', 0)} levels")
        
        self.assert_true(True, "High-volume operations successful")
        
        store.close()
    
    def test_interleaved_operations(self):
        """Test interleaved PUTs, GETs, and DELETEs."""
        print("\nTest 16: Interleaved Operations")
        print("-" * 60)
        
        store = LSMKVStore(data_dir=self.test_dir, memtable_size=1000)
        
        # Interleave operations
        for i in range(20):
            store.put(f"inter_{i}", f"v{i}")
            
            if i % 3 == 0:
                result = store.get(f"inter_{i}")
                self.assert_true(result.found, f"inter_{i} found immediately after PUT")
            
            if i % 5 == 0 and i > 0:
                store.delete(f"inter_{i-1}")
                result = store.get(f"inter_{i-1}")
                self.assert_true(not result.found, f"inter_{i-1} deleted")
        
        self.assert_true(True, "Interleaved operations work correctly")
        
        store.close()
    
    def test_stress_leveled_compaction(self):
        """Stress test leveled compaction with rapid writes."""
        print("\nTest 17: Stress Test Leveled Compaction")
        print("-" * 60)
        
        store = LSMKVStore(
            data_dir=self.test_dir,
            memtable_size=10,
            level_ratio=5,
            base_level_entries=20,
            max_l0_sstables=3
        )
        
        # Rapid writes
        for i in range(100):
            store.put(f"stress_{i:04d}", f"value_{i}")
        
        time.sleep(3)  # Wait for all compactions
        
        # Verify no data loss
        for i in range(100):
            result = store.get(f"stress_{i:04d}")
            self.assert_true(result.found, f"stress_{i:04d} survived compactions")
        
        level_info = store.get_level_info()
        print(f"  Level distribution after stress:")
        for level, info in sorted(level_info.items()):
            if info['sstables'] > 0:
                print(f"    L{level}: {info['sstables']} SSTable(s), {info['entries']} entries")
        
        store.close()
    
    def test_zero_write_blocking(self):
        """Test that writes never block during background operations."""
        print("\nTest 18: Zero Write Blocking")
        print("-" * 60)
        
        store = LSMKVStore(
            data_dir=self.test_dir,
            memtable_size=5,
            max_l0_sstables=2  # Trigger frequent compactions
        )
        
        # Measure write latency
        latencies = []
        
        for i in range(50):
            start = time.time()
            store.put(f"blocking_test_{i}", f"value_{i}")
            latency = time.time() - start
            latencies.append(latency)
        
        max_latency = max(latencies)
        avg_latency = sum(latencies) / len(latencies)
        
        print(f"  Max write latency: {max_latency*1000:.2f}ms")
        print(f"  Avg write latency: {avg_latency*1000:.2f}ms")
        
        # No write should block for long
        self.assert_true(max_latency < 0.1, f"Max latency acceptable ({max_latency*1000:.1f}ms < 100ms)")
        
        store.close()
    
    def test_multiple_restarts(self):
        """Test multiple restart cycles."""
        print("\nTest 19: Multiple Restart Cycles")
        print("-" * 60)
        
        data_to_verify = {}
        
        # Cycle 1
        store1 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        for i in range(10):
            store1.put(f"cycle1_{i}", f"v1_{i}")
            data_to_verify[f"cycle1_{i}"] = f"v1_{i}"
        time.sleep(1)
        store1.close()
        
        # Cycle 2
        store2 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        for i in range(10):
            store2.put(f"cycle2_{i}", f"v2_{i}")
            data_to_verify[f"cycle2_{i}"] = f"v2_{i}"
        time.sleep(1)
        store2.close()
        
        # Cycle 3
        store3 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        for i in range(10):
            store3.put(f"cycle3_{i}", f"v3_{i}")
            data_to_verify[f"cycle3_{i}"] = f"v3_{i}"
        time.sleep(1)
        store3.close()
        
        # Final verification
        store4 = LSMKVStore(data_dir=self.test_dir, memtable_size=5)
        
        for key, expected_value in data_to_verify.items():
            result = store4.get(key)
            self.assert_true(result.found, f"{key} found after multiple restarts")
            self.assert_true(result.value == expected_value, f"{key} value correct")
        
        store4.close()
    
    def test_configuration_variations(self):
        """Test different configuration combinations."""
        print("\nTest 20: Configuration Variations")
        print("-" * 60)
        
        configs = [
            {"level_ratio": 5, "max_l0_sstables": 2},
            {"level_ratio": 10, "max_l0_sstables": 4},
            {"level_ratio": 20, "max_l0_sstables": 8},
        ]
        
        for i, config in enumerate(configs):
            test_dir = os.path.join(self.test_dir, f"config_{i}")
            
            store = LSMKVStore(
                data_dir=test_dir,
                memtable_size=5,
                **config
            )
            
            # Add data
            for j in range(20):
                store.put(f"key{j}", f"value{j}")
            
            time.sleep(1)
            
            # Verify works
            result = store.get("key10")
            self.assert_true(result.found, f"Config {i} works: {config}")
            
            store.close()
    
    def run_all_tests(self):
        """Run all tests."""
        print("=" * 70)
        print("END-TO-END - COMPREHENSIVE TEST SUITE")
        print("=" * 70)
        
        self.setup()
        
        try:
            self.test_put_get_delete_cycle()
            self.test_memtable_to_sstable_flow()
            self.test_wal_recovery()
            self.test_sstable_recovery()
            self.test_update_override()
            self.test_concurrent_operations()
            self.test_large_dataset()
            self.test_bloom_filter_effectiveness()
            self.test_leveled_compaction_flow()
            self.test_manual_vs_auto_flush()
            self.test_compaction_preserves_latest()
            self.test_interleaved_operations()
            self.test_stress_leveled_compaction()
            self.test_zero_write_blocking()
            self.test_multiple_restarts()
            self.test_configuration_variations()
            
        finally:
            self.teardown()
        
        print("\n" + "=" * 70)
        print(f"RESULTS: {self.passed} passed, {self.failed} failed")
        print("=" * 70)
        
        return self.failed == 0


if __name__ == "__main__":
    tester = TestEndToEnd()
    success = tester.run_all_tests()
    
    # Cleanup
    if hasattr(tester, 'test_dir') and tester.test_dir:
        shutil.rmtree(tester.test_dir, ignore_errors=True)
    
    sys.exit(0 if success else 1)
